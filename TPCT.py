import sys
import string
import re
import nltk
import spacy
import sqlite3
import time
from collections import Counter
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer, PorterStemmer

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Load Spacy model for Named Entity Recognition
nlp = spacy.load("en_core_web_sm")

# Initialize NLP tools
lemmatizer = WordNetLemmatizer()
stemmer = PorterStemmer()
stop_words = set(stopwords.words("english"))

# Loading animation function
def loading_animation():
    spinner = ["|", "/", "-", "\\"]
    for _ in range(2):  # Rotate 2 times
        for symbol in spinner:
            print(f"\rProcessing {symbol}", end="", flush=True)
            time.sleep(0.2)  # Adjust speed if needed
    print("\rProcessing complete!    ")  # Clear last spinner frame

if len(sys.argv) > 1:
    filename = sys.argv[1]
    print("Filename received:", filename)

    try:
        with open(filename, "r", encoding="utf-8") as file:
            content = file.read()

            # ğŸ”¹ Remove punctuation
            clean_content = content.translate(str.maketrans('', '', string.punctuation))

            # ğŸ”¹ Tokenize words
            words = clean_content.split()

            # ğŸ”¹ Count Sentences
            sentences = re.split(r'[.!?]+', content)
            sentences = [s.strip() for s in sentences if s.strip()]

            # ğŸ”¹ Count Paragraphs
            paragraphs = content.split("\n\n")
            paragraphs = [p.strip() for p in paragraphs if p.strip()]

            # ğŸ”¹ Stop-word Removal
            filtered_words = [word for word in words if word.lower() not in stop_words]

            # ğŸ”¹ Stemming
            stemmed_words = [stemmer.stem(word) for word in filtered_words]

            # ğŸ”¹ Lemmatization
            lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]

            # ğŸ”¹ Word Frequency Analysis
            word_counts = Counter(lemmatized_words)
            most_common_words = word_counts.most_common(10)

            # ğŸ”¹ Named Entity Recognition (NER)
            doc = nlp(content)
            entities = [(ent.text, ent.label_) for ent in doc.ents]

            print("âœ… Analysis stored in SQLite database: text_analysis.db")

            # ğŸ”¹ INTERACTIVE MENU FOR USER INPUT
            def display_menu():
                print("\nğŸ“„ TEXT PROCESSING TOOL")
                print("=" * 50)
                print("1ï¸âƒ£ Basic Statistics")
                print("2ï¸âƒ£ Words AFTER Stop-word Removal")
                print("3ï¸âƒ£ Words AFTER Stemming & Lemmatization")
                print("4ï¸âƒ£ Top 10 Most Common Words")
                print("5ï¸âƒ£ Named Entity Recognition (NER)")
                print("6ï¸âƒ£ Save Results & Exit")
                print("=" * 50)

            display_menu()  # Show the full menu once

            while True:
                choice = input("\nğŸ”¹ Enter your choice (1-5) to choose an option, (M) Main Menu, or (Q) Quit: ").strip().lower()

                if choice in ["1", "2", "3", "4", "5"]:
                    loading_animation()

                if choice == "1":
                    print("\nğŸ“ Basic Statistics")
                    print("-" * 50)
                    print(f"Total Words: {len(words)}")
                    print(f"Total Sentences: {len(sentences)}")
                    print(f"Total Paragraphs: {len(paragraphs)}")
                elif choice == "2":
                    print("\nğŸš« Words AFTER Stop-word Removal")
                    print("-" * 50)
                    print(" ".join(filtered_words))
                elif choice == "3":
                    print("\nğŸŒ± Words AFTER Stemming & Lemmatization")
                    print("-" * 50)
                    print("Stemming: " + " ".join(stemmed_words))
                    print("Lemmatization: " + " ".join(lemmatized_words))
                elif choice == "4":
                    print("\nğŸ“Š Top 10 Most Common Words")
                    print("-" * 50)
                    for word, count in most_common_words:
                        print(f"{word}: {count} times")
                elif choice == "5":
                    print("\nğŸ· Named Entities Recognized")
                    print("-" * 50)
                    for entity, label in entities:
                        print(f"{entity} â†’ {label}")
                elif choice == "6" or choice == "q":
                    print("\nğŸ”¹ Exiting program. Goodbye! ğŸ‘‹")
                    break
                elif choice == "m":
                    display_menu()
                else:
                    print("\nâŒ Invalid choice. Returning to options...")

    except FileNotFoundError:
        print(f"\nâŒ Error: The file '{filename}' was not found.")
    except Exception as e:
        print(f"\nâŒ An error occurred: {e}")

else:
    print("No filename provided.")
